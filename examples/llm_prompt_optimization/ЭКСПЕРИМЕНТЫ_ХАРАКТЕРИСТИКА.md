# Характеристика экспериментов по оптимизации промптов

## Общая информация

Все эксперименты проводились с использованием OpenEvolve для автоматической эволюции промптов для различных задач NLP. Использовались каскадная оценка (2-стадийная), LLM feedback для качественной оценки промптов, и MAP-Elites алгоритм для поддержания разнообразия.

---

## 1. IFEval (Instruction Following Evaluation)

### Задача
**Следование сложным инструкциям с множественными ограничениями** — модель должна точно выполнить инструкцию, содержащую несколько требований (форматирование, запреты, перечисления, ограничения длины и т.д.).

### Датасет
- **Источник**: `google/IFEval` (HuggingFace)
- **Размер**: 541 пример (train split)
- **Тип**: Instruction following с 25 типами ограничений
- **Метрика**: Бинарная проверка соответствия всем ограничениям инструкции
- **Особенности**: Каждая инструкция содержит список `instruction_id_list` с типами ограничений (keywords, length_constraints, format, punctuation и др.)

### Результаты
- **Baseline accuracy**: 95.01% (514/541)
- **Evolved accuracy**: 97.41% (527/541)
- **Улучшение**: **+2.40%** ✅
- **Пустые ответы**: 16 → 13 (улучшение на 18.75%)

### Выводы
Эволюция промпта улучшила способность модели следовать сложным инструкциям. Лучший промпт стал более структурированным с явными требованиями к формату ответа и пошаговым рассуждением.

---

## 2. HoVer (Claim Verification)

### Задача
**Верификация утверждений** — определение, является ли утверждение SUPPORTED (подтверждено) или NOT_SUPPORTED (не подтверждено) на основе фактов из предоставленных источников.

### Датасет
- **Источник**: `hover-nlp/hover` (HuggingFace)
- **Размер**: 4,000 примеров (validation split)
- **Тип**: Multi-hop reasoning для фактчекинга
- **Метрика**: Бинарная классификация (SUPPORTED/NOT_SUPPORTED)
- **Особенности**: Требует анализа нескольких документов и многошагового рассуждения. Использует integer labels (0=SUPPORTED, 1=NOT_SUPPORTED)

### Результаты
- **Baseline accuracy**: 43.83% (1753/4000)
- **Evolved accuracy**: 42.90% (1716/4000)
- **Изменение**: **-0.93%** ❌
- **Пустые ответы**: 15 → 2 (улучшение на 86.67%)

### Выводы
Эволюция не привела к улучшению точности, возможно из-за высокой сложности задачи. Однако значительно сократилось количество пустых ответов. Задача требует более специализированных стратегий промптов для многошагового рассуждения.

---

## 3. HotpotQA (Multi-hop Question Answering)

### Задача
**Многошаговое рассуждение для ответов на вопросы** — ответ на вопрос, требующий синтеза информации из нескольких параграфов контекста.

### Датасет
- **Источник**: `hotpot_qa` (HuggingFace)
- **Размер**: 7,405 примеров (validation split)
- **Тип**: Multi-hop question answering
- **Метрика**: Exact match с правильным ответом
- **Особенности**: Каждый вопрос требует анализа нескольких параграфов и синтеза информации

### Результаты
- **Baseline accuracy**: 77.93% (5771/7405)
- **Evolved accuracy**: 88.62% (6562/7405)
- **Улучшение**: **+10.69%** ✅ **Лучший результат!**
- **Пустые ответы**: 110 → 72 (улучшение на 34.55%)

### Выводы
**Наибольшее улучшение среди всех экспериментов.** Эволюция создала структурированный промпт с явными шагами: анализ параграфов, синтез информации, цитирование источников. Это показывает, что для сложных задач многошагового рассуждения структурированные промпты критически важны.

### Лучший промпт (фрагмент)
```
Answer the following question using the provided context. The answer requires synthesizing information from multiple paragraphs.

Carefully analyze the context, extracting key details from each paragraph that are directly relevant to the question. Explicitly connect insights across sections and reason step by step...
```

---

## 4. GPQA (Graduate-Level Google-Proof Q&A)

### Задача
**Научное рассуждение в STEM** — ответы на сложные вопросы с множественным выбором по биологии, физике и химии на уровне аспирантуры/PhD.

### Датасет
- **Источник**: `Idavidrein/gpqa` (HuggingFace)
- **Размер**: 448 вопросов (198 в Diamond subset)
- **Тип**: Multiple choice (4 варианта)
- **Метрика**: Accuracy по правильному выбору ответа
- **Особенности**: Вопросы специально разработаны так, чтобы их нельзя было решить простым поиском в интернете

### Статус
**Анализ проведен, эксперимент не реализован**

### Анализ применимости
- **Релевантность для IF**: ⭐⭐ (низкая) — это задача STEM reasoning, а не instruction following
- **Baseline моделей**: GPT-4 ~39%, Claude 3 Opus ~50%, Grok 4 ~87.5%
- **Рекомендация**: Не использовать как основной бенчмарк для IF, но может быть полезен для отдельного эксперимента по эволюции reasoning промптов

---

## 5. LiveBench Instruction Following

### Задача
**Следование инструкциям (расширенная версия IFEval)** — содержит как оригинальный IFEval формат (25 типов ограничений), так и новый IFBench формат (58 дополнительных типов ограничений).

### Датасет
- **Источник**: `livebench/instruction_following` (HuggingFace)
- **Размер**: Варьируется по релизам (обновляется ежемесячно)
- **Тип**: Instruction following с 83 типами ограничений (25 + 58)
- **Метрика**: Бинарная проверка соответствия ограничениям
- **Особенности**: Регулярные обновления, защита от contamination, готовые скрипты оценки

### Статус
**Анализ проведен, эксперимент не реализован**

### Преимущества
- Содержит оба формата: IFEval + IFBench
- Готовые скрипты оценки
- Регулярные обновления
- Объективные метрики

---

## 6. MuSR (Multistep Soft Reasoning)

### Задача
**Многошаговое мягкое рассуждение** — решение задач, требующих цепочек рассуждений в контексте длинных естественных языковых повествований (~1000 слов).

### Датасет
- **Источник**: `TAUR-Lab/MuSR` (HuggingFace)
- **Размер**: ~2500+ примеров (3 типа задач)
- **Тип**: Multiple choice с длинными нарративами
- **Метрика**: Accuracy по правильному выбору ответа
- **Типы задач**:
  1. Murder Mysteries (детективные истории)
  2. Object Placements (отслеживание объектов)
  3. Team Allocation (распределение по командам)

### Статус
**Анализ проведен, эксперимент не реализован**

### Анализ применимости
- **Релевантность для Reasoning**: ⭐⭐⭐⭐⭐ (отлично) — прямая задача multi-step reasoning
- **Baseline моделей**: GPT-4 ~57%, Claude 3 Opus ~67%
- **Рекомендация**: Отлично подходит для эволюции Chain-of-Thought промптов

---

## 7. WILDS Amazon (Sentiment Classification)

### Задача
**Классификация тональности отзывов** — определение рейтинга отзыва (1-5 звёзд) на основе текста.

### Датасет
- **Источник**: WILDS benchmark (Stanford)
- **Размер**: 245,502 отзыва в train, 100,050 в validation/test (OOD)
- **Тип**: Sentiment classification с domain shift
- **Метрика**: Accuracy, Macro F1, MAE (Mean Absolute Error)
- **Особенности**: 
  - **User-disjoint split**: отзывы одного пользователя только в одной группе (train/test)
  - 26 категорий товаров (Books доминирует — 74.4%)
  - Дисбаланс классов: 5⭐=57.5%, 1⭐=1.1%

### Результаты
- **Категория**: Office_Products (1,298 отзывов)
- **Эксперимент**: Эволюция промпта для конкретной категории
- **Особенности**: Использование few-shot примеров, автоматическая генерация примеров на основе схожести

### Выводы
Эксперимент демонстрирует возможность эволюции промптов для задач классификации с учетом специфики домена. Особое внимание уделено работе с domain shift по пользователям.

---

## Сводная таблица результатов

| Эксперимент | Задача | Датасет | Baseline | Evolved | Улучшение | Статус |
|------------|--------|---------|----------|---------|-----------|--------|
| **IFEval** | Instruction Following | 541 пример | 95.01% | 97.41% | **+2.40%** ✅ | ✅ Реализован |
| **HoVer** | Claim Verification | 4,000 примеров | 43.83% | 42.90% | -0.93% ❌ | ✅ Реализован |
| **HotpotQA** | Multi-hop QA | 7,405 примеров | 77.93% | 88.62% | **+10.69%** ✅ | ✅ Реализован |
| **GPQA** | STEM Reasoning | 448 вопросов | - | - | - | ⚠️ Анализ |
| **LiveBench IF** | Instruction Following | Варьируется | - | - | - | ⚠️ Анализ |
| **MuSR** | Soft Reasoning | ~2500 примеров | - | - | - | ⚠️ Анализ |
| **WILDS Amazon** | Sentiment Classification | 245,502 отзыва | - | - | - | ✅ Реализован |

---

## Общие выводы

### Успешные эксперименты
1. **HotpotQA** показал наибольшее улучшение (+10.69%), что демонстрирует эффективность эволюции для сложных задач многошагового рассуждения.
2. **IFEval** достиг near-perfect performance (97.41%), показывая, что эволюция может улучшить даже уже хорошо работающие промпты.

### Сложные случаи
1. **HoVer** не показал улучшения, возможно из-за высокой сложности задачи и необходимости более специализированных стратегий.

### Ключевые техники
- **Cascade Evaluation**: Экономия ~75% времени и API вызовов
- **LLM Feedback**: Улучшение обобщающей способности промптов
- **MAP-Elites**: Поддержание разнообразия стратегий промптов
- **Full Rewrite Mode**: Лучше для текстовых промптов, чем diff-based модификации

### Общая статистика (GEPA Benchmarks)
- **Baseline aggregate**: 67.29% (8038/11946)
- **Evolved aggregate**: 73.71% (8805/11946)
- **Общее улучшение**: **+6.42%** ✅
- **Дополнительно**: 38% меньше пустых ответов

---

*Отчет создан: Декабрь 2025*
*Версия: 1.0*


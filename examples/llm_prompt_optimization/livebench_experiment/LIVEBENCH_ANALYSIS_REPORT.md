# –ê–Ω–∞–ª–∏–∑ LiveBench –¥–ª—è —ç–≤–æ–ª—é—Ü–∏–∏ –ø—Ä–æ–º–ø—Ç–æ–≤

## üìã –°–æ–¥–µ—Ä–∂–∞–Ω–∏–µ
1. [–û–±–∑–æ—Ä —Å—Ç—Ä—É–∫—Ç—É—Ä—ã —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è](#–æ–±–∑–æ—Ä-—Å—Ç—Ä—É–∫—Ç—É—Ä—ã-—Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è)
2. [–î–æ—Å—Ç—É–ø–Ω—ã–µ –¥–∞—Ç–∞—Å–µ—Ç—ã –∏ –∏—Ö —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å](#–¥–æ—Å—Ç—É–ø–Ω—ã–µ-–¥–∞—Ç–∞—Å–µ—Ç—ã-–∏-–∏—Ö-—Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å)
3. [–ì–æ—Ç–æ–≤—ã–µ —Å–∫—Ä–∏–ø—Ç—ã –æ—Ü–µ–Ω–∫–∏](#–≥–æ—Ç–æ–≤—ã–µ-—Å–∫—Ä–∏–ø—Ç—ã-–æ—Ü–µ–Ω–∫–∏)
4. [–†–µ–∫–æ–º–µ–Ω–¥—É–µ–º—ã–π –¥–∞—Ç–∞—Å–µ—Ç –¥–ª—è —ç–≤–æ–ª—é—Ü–∏–∏ –ø—Ä–æ–º–ø—Ç–æ–≤](#—Ä–µ–∫–æ–º–µ–Ω–¥—É–µ–º—ã–π-–¥–∞—Ç–∞—Å–µ—Ç-–¥–ª—è-—ç–≤–æ–ª—é—Ü–∏–∏-–ø—Ä–æ–º–ø—Ç–æ–≤)
5. [–°–∫–æ—Ä—Ä–µ–∫—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –ø–ª–∞–Ω —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏](#—Å–∫–æ—Ä—Ä–µ–∫—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–π-–ø–ª–∞–Ω-—Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏)
6. [–°—Ç—Ä—É–∫—Ç—É—Ä–∞ —Ñ–∞–π–ª–æ–≤ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞](#—Å—Ç—Ä—É–∫—Ç—É—Ä–∞-—Ñ–∞–π–ª–æ–≤-—ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞)

---

## üóÇÔ∏è –û–±–∑–æ—Ä —Å—Ç—Ä—É–∫—Ç—É—Ä—ã —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è

```
LiveBench/
‚îú‚îÄ‚îÄ livebench/
‚îÇ   ‚îú‚îÄ‚îÄ if_runner/                    # üéØ –ì–õ–ê–í–ù–û–ï: Instruction Following
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ifbench/                  # IFBench (–Ω–æ–≤—ã–π, —Å–ª–æ–∂–Ω—ã–π)
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ evaluation_lib.py     # ‚úÖ –ì–æ—Ç–æ–≤—ã–π —Å–∫—Ä–∏–ø—Ç –æ—Ü–µ–Ω–∫–∏
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ instructions.py       # 58 –Ω–æ–≤—ã—Ö –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–π
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ instructions_registry.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ instruction_following_eval/  # IFEval (–æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π Google)
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ evaluation_main.py    # ‚úÖ –ì–æ—Ç–æ–≤—ã–π —Å–∫—Ä–∏–ø—Ç –æ—Ü–µ–Ω–∫–∏
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ instructions.py       # –û—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–µ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è
‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ instructions_registry.py
‚îÇ   ‚îú‚îÄ‚îÄ process_results/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ instruction_following/
‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ utils.py              # ‚úÖ –§—É–Ω–∫—Ü–∏–∏ –ø–æ–¥—Å—á—ë—Ç–∞ —Å–∫–æ—Ä–∞
‚îÇ   ‚îú‚îÄ‚îÄ gen_api_answer.py             # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–æ–≤ —á–µ—Ä–µ–∑ API
‚îÇ   ‚îú‚îÄ‚îÄ gen_ground_truth_judgment.py  # –û—Ü–µ–Ω–∫–∞ –æ—Ç–≤–µ—Ç–æ–≤
‚îÇ   ‚îú‚îÄ‚îÄ run_livebench.py              # –ì–ª–∞–≤–Ω—ã–π —Å–∫—Ä–∏–ø—Ç –∑–∞–ø—É—Å–∫–∞
‚îÇ   ‚îî‚îÄ‚îÄ download_questions.py         # –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–æ–≤
‚îî‚îÄ‚îÄ README.md
```

---

## üìä –î–æ—Å—Ç—É–ø–Ω—ã–µ –¥–∞—Ç–∞—Å–µ—Ç—ã –∏ –∏—Ö —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å

### HuggingFace –¥–∞—Ç–∞—Å–µ—Ç—ã LiveBench

| –ö–∞—Ç–µ–≥–æ—Ä–∏—è | HuggingFace –ø—É—Ç—å | –†–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å | –û–ø–∏—Å–∞–Ω–∏–µ |
|-----------|------------------|---------------|----------|
| **Instruction Following** | `livebench/instruction_following` | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | **–ò–î–ï–ê–õ–¨–ù–û** ‚Äî –ø—Ä—è–º–∞—è –∑–∞–¥–∞—á–∞ —Å–ª–µ–¥–æ–≤–∞–Ω–∏—è –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—è–º |
| Reasoning | `livebench/reasoning` | ‚≠ê‚≠ê‚≠ê | –õ–æ–≥–∏—á–µ—Å–∫–∏–µ –≥–æ–ª–æ–≤–æ–ª–æ–º–∫–∏ (web_of_lies, zebra_puzzle) |
| Math | `livebench/math` | ‚≠ê‚≠ê | –ú–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ —Å–æ—Ä–µ–≤–Ω–æ–≤–∞–Ω–∏—è |
| Coding | `livebench/coding` | ‚≠ê | –¢—Ä–µ–±—É–µ—Ç Docker, —Å–ª–æ–∂–Ω–∞—è –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è |
| Language | `livebench/language` | ‚≠ê‚≠ê | Typos, connections, plot_unscrambling |
| Data Analysis | `livebench/data_analysis` | ‚≠ê‚≠ê | –†–∞–±–æ—Ç–∞ —Å —Ç–∞–±–ª–∏—Ü–∞–º–∏ |

### –î–≤–∞ —Ñ–æ—Ä–º–∞—Ç–∞ Instruction Following –≤ LiveBench

#### 1. **IFEval —Ñ–æ—Ä–º–∞—Ç** (–æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π Google)
- **–ò—Å—Ç–æ—á–Ω–∏–∫**: `livebench/if_runner/instruction_following_eval/`
- **–¢–∏–ø—ã –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–π** (25 —Ç–∏–ø–æ–≤):
  - `keywords:existence` ‚Äî –Ω–∞–ª–∏—á–∏–µ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤
  - `keywords:forbidden_words` ‚Äî –∑–∞–ø—Ä–µ—â—ë–Ω–Ω—ã–µ —Å–ª–æ–≤–∞
  - `length_constraints:number_words` ‚Äî –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–ª–æ–≤
  - `length_constraints:number_sentences` ‚Äî –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π
  - `length_constraints:number_paragraphs` ‚Äî –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–∞—Ä–∞–≥—Ä–∞—Ñ–æ–≤
  - `detectable_format:json_format` ‚Äî JSON —Ñ–æ—Ä–º–∞—Ç
  - `detectable_format:number_bullet_lists` ‚Äî —Å–ø–∏—Å–∫–∏
  - `change_case:english_capital` ‚Äî –∑–∞–≥–ª–∞–≤–Ω—ã–µ –±—É–∫–≤—ã
  - `punctuation:no_comma` ‚Äî –±–µ–∑ –∑–∞–ø—è—Ç—ã—Ö
  - –ò –¥—Ä—É–≥–∏–µ...

#### 2. **IFBench —Ñ–æ—Ä–º–∞—Ç** (–Ω–æ–≤—ã–π, —Å–ª–æ–∂–Ω–µ–µ)
- **–ò—Å—Ç–æ—á–Ω–∏–∫**: `livebench/if_runner/ifbench/`
- **58 –Ω–æ–≤—ã—Ö –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–π** (–ø—Ä–∏–º–µ—Ä—ã):
  - `count:word_count_range` ‚Äî –¥–∏–∞–ø–∞–∑–æ–Ω –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ —Å–ª–æ–≤
  - `count:unique_word_count` ‚Äî —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ —Å–ª–æ–≤–∞
  - `ratio:sentence_type` ‚Äî —Å–æ–æ—Ç–Ω–æ—à–µ–Ω–∏–µ —Ç–∏–ø–æ–≤ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π
  - `words:alphabet` ‚Äî —Å–ª–æ–≤–∞ –ø–æ –∞–ª—Ñ–∞–≤–∏—Ç—É
  - `words:palindrome` ‚Äî –ø–∞–ª–∏–Ω–¥—Ä–æ–º—ã
  - `sentence:alliteration_increment` ‚Äî –∞–ª–ª–∏—Ç–µ—Ä–∞—Ü–∏—è
  - `format:parentheses` ‚Äî –≤–ª–æ–∂–µ–Ω–Ω—ã–µ —Å–∫–æ–±–∫–∏
  - `format:emoji` ‚Äî —ç–º–æ–¥–∑–∏ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è
  - –ò –¥—Ä—É–≥–∏–µ...

---

## ‚úÖ –ì–æ—Ç–æ–≤—ã–µ —Å–∫—Ä–∏–ø—Ç—ã –æ—Ü–µ–Ω–∫–∏

### 1. –û—Å–Ω–æ–≤–Ω–æ–π —Å–∫—Ä–∏–ø—Ç –æ—Ü–µ–Ω–∫–∏ IF

**–§–∞–π–ª**: `livebench/process_results/instruction_following/utils.py`

```python
def score_results(follow_all_instructions, follow_instruction_list, threshold=0.2):
    """
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–∫–æ—Ä –æ—Ç 0 –¥–æ 1:
    - score_1: 1 –µ—Å–ª–∏ –≤—Å–µ –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω—ã, –∏–Ω–∞—á–µ 0
    - score_2: –¥–æ–ª—è –≤—ã–ø–æ–ª–Ω–µ–Ω–Ω—ã—Ö –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–π
    - avg_score: —Å—Ä–µ–¥–Ω–µ–µ score_1 –∏ score_2
    """
    score_1 = 1 if follow_all_instructions else 0
    score_2 = sum([1 if follow else 0 for follow in follow_instruction_list]) / len(follow_instruction_list)
    avg_score = (score_1 + score_2) / 2
    return avg_score

def ifbench_process_results(question, llm_answer, debug=False) -> float:
    """–û—Ü–µ–Ω–∫–∞ –¥–ª—è IFBench —Ñ–æ—Ä–º–∞—Ç–∞."""
    # –ò—Å–ø–æ–ª—å–∑—É–µ—Ç evaluation_lib.test_instruction_following_strict()
    ...

def instruction_following_process_results(questions, model_answers, task, model_id, debug=False):
    """–û—Ü–µ–Ω–∫–∞ –¥–ª—è IFEval —Ñ–æ—Ä–º–∞—Ç–∞."""
    # –ò—Å–ø–æ–ª—å–∑—É–µ—Ç evaluation_main.evaluator()
    ...
```

### 2. IFEval –æ—Ü–µ–Ω–∫–∞ (–æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–∞—è Google)

**–§–∞–π–ª**: `livebench/if_runner/instruction_following_eval/evaluation_main.py`

```python
def test_instruction_following_strict(inp, prompt_to_response):
    """–°—Ç—Ä–æ–≥–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞: –≤—Å–µ –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏ –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å –≤—ã–ø–æ–ª–Ω–µ–Ω—ã."""
    ...

def test_instruction_following_loose(inp, prompt_to_response):
    """–ú—è–≥–∫–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞: –ø—Ä–æ–±—É–µ—Ç —Ä–∞–∑–Ω—ã–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã –æ—Ç–≤–µ—Ç–∞."""
    ...

def evaluator(questions, model_answers, _OUTPUT_DIR, model_id):
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –æ—Ü–µ–Ω–∫–∏."""
    ...
```

### 3. IFBench –æ—Ü–µ–Ω–∫–∞ (–Ω–æ–≤–∞—è, —Å–ª–æ–∂–Ω–µ–µ)

**–§–∞–π–ª**: `livebench/if_runner/ifbench/evaluation_lib.py`

```python
def test_instruction_following_strict(inp: InputExample, response: str):
    """–°—Ç—Ä–æ–≥–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ IFBench –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–π."""
    ...

def test_instruction_following_loose(inp: InputExample, response: str):
    """–ú—è–≥–∫–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ IFBench –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–π."""
    ...
```

---

## üéØ –†–µ–∫–æ–º–µ–Ω–¥—É–µ–º—ã–π –¥–∞—Ç–∞—Å–µ—Ç –¥–ª—è —ç–≤–æ–ª—é—Ü–∏–∏ –ø—Ä–æ–º–ø—Ç–æ–≤

### –í—ã–±–æ—Ä: **LiveBench Instruction Following**

| –ö—Ä–∏—Ç–µ—Ä–∏–π | IFEval (–Ω–∞—à —Ç–µ–∫—É—â–∏–π) | LiveBench IF |
|----------|---------------------|--------------|
| **–ì–æ—Ç–æ–≤—ã–µ —Å–∫—Ä–∏–ø—Ç—ã –æ—Ü–µ–Ω–∫–∏** | ‚úÖ Google | ‚úÖ LiveBench (—Å–æ–¥–µ—Ä–∂–∏—Ç –æ–±–∞!) |
| **–û–±—ä–µ–∫—Ç–∏–≤–Ω–∞—è –æ—Ü–µ–Ω–∫–∞** | ‚úÖ | ‚úÖ |
| **–°–ª–æ–∂–Ω–æ—Å—Ç—å –∑–∞–¥–∞—á** | –°—Ä–µ–¥–Ω—è—è | –í—ã—à–µ (IFBench) |
| **–†–∞–∑–Ω–æ–æ–±—Ä–∞–∑–∏–µ** | 25 —Ç–∏–ø–æ–≤ | 25 + 58 = 83 —Ç–∏–ø–∞ |
| **–ó–∞—â–∏—Ç–∞ –æ—Ç contamination** | ‚ùå –°—Ç–∞—Ç–∏—á–Ω—ã–π | ‚úÖ –û–±–Ω–æ–≤–ª—è–µ—Ç—Å—è |
| **–†–∞–∑–º–µ—Ä –¥–∞—Ç–∞—Å–µ—Ç–∞** | 541 –ø—Ä–∏–º–µ—Ä–æ–≤ | –í–∞—Ä—å–∏—Ä—É–µ—Ç—Å—è –ø–æ —Ä–µ–ª–∏–∑–∞–º |

### –ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞ LiveBench IF:
1. ‚úÖ **–°–æ–¥–µ—Ä–∂–∏—Ç –æ–±–∞ —Ñ–æ—Ä–º–∞—Ç–∞**: IFEval + IFBench
2. ‚úÖ **–ì–æ—Ç–æ–≤—ã–µ —Å–∫—Ä–∏–ø—Ç—ã –æ—Ü–µ–Ω–∫–∏** ‚Äî –Ω–µ –Ω—É–∂–Ω–æ –ø–∏—Å–∞—Ç—å —Å–≤–æ–∏
3. ‚úÖ **–†–µ–≥—É–ª—è—Ä–Ω—ã–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è** ‚Äî –Ω–æ–≤—ã–µ –∑–∞–¥–∞—á–∏ –∫–∞–∂–¥—ã–π –º–µ—Å—è—Ü
4. ‚úÖ **–û–±—ä–µ–∫—Ç–∏–≤–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏** ‚Äî –±–µ–∑ LLM-—Å—É–¥—å–∏
5. ‚úÖ **–°–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å** ‚Äî –∏—Å–ø–æ–ª—å–∑—É–µ—Ç —Ç–æ—Ç –∂–µ API —á—Ç–æ –∏ –Ω–∞—à ifeval_experiment

---

## üìê –°–∫–æ—Ä—Ä–µ–∫—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –ø–ª–∞–Ω —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏

### –§–∞–∑–∞ 1: –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ (1-2 —á–∞—Å–∞)

#### 1.1. –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π

```bash
cd livebench_experiment/LiveBench
pip install -e .
```

#### 1.2. –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞

```bash
cd livebench
python download_questions.py
```

–î–∞—Ç–∞—Å–µ—Ç –±—É–¥–µ—Ç –∑–∞–≥—Ä—É–∂–µ–Ω –≤: `livebench/data/live_bench/instruction_following/`

#### 1.3. –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –≤–æ–ø—Ä–æ—Å–æ–≤

```json
{
  "question_id": "abc123...",
  "category": "instruction_following",
  "task": "ifeval_v2",  // –∏–ª–∏ "ifbench"
  "turns": ["Your instruction prompt here..."],
  "instruction_id_list": ["keywords:existence", "length_constraints:number_words"],
  "kwargs": [{"keywords": ["example"]}, {"num_words": 100}],
  "ground_truth": null  // –û—Ü–µ–Ω–∫–∞ —á–µ—Ä–µ–∑ check_following()
}
```

### –§–∞–∑–∞ 2: –°–æ–∑–¥–∞–Ω–∏–µ evaluator.py (2-3 —á–∞—Å–∞)

```python
"""
Evaluator for LiveBench Instruction Following prompt optimization.
–ò—Å–ø–æ–ª—å–∑—É–µ—Ç –û–§–ò–¶–ò–ê–õ–¨–ù–´–ï —Å–∫—Ä–∏–ø—Ç—ã –æ—Ü–µ–Ω–∫–∏ LiveBench.
"""

import os
import sys
import random
from typing import Dict, Any, Tuple, List

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –∫ LiveBench
LIVEBENCH_PATH = os.path.join(os.path.dirname(__file__), "LiveBench", "livebench")
sys.path.insert(0, LIVEBENCH_PATH)

from if_runner.instruction_following_eval import evaluation_main
from if_runner.ifbench import evaluation_lib
from process_results.instruction_following.utils import score_results, ifbench_process_results

# –ì–ª–æ–±–∞–ª—å–Ω—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ
_DATASET_SPLITS = {}
CACHE_DIR = os.path.join(os.path.dirname(__file__), ".evaluation_cache")


def load_livebench_if_dataset(config: Dict) -> Tuple[List, List, List]:
    """
    –ó–∞–≥—Ä—É–∑–∫–∞ –∏ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ LiveBench IF –¥–∞—Ç–∞—Å–µ—Ç–∞.
    """
    from datasets import load_dataset
    
    cache_key = "livebench_if"
    if cache_key in _DATASET_SPLITS:
        return (_DATASET_SPLITS[cache_key]["train"],
                _DATASET_SPLITS[cache_key]["validation"],
                _DATASET_SPLITS[cache_key]["test"])
    
    # –ó–∞–≥—Ä—É–∑–∫–∞ —Å HuggingFace
    dataset = load_dataset("livebench/instruction_following", split="test")
    
    # –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –ø–æ —Ä–µ–ª–∏–∑—É (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
    release = config.get("livebench_release", "2024-11-25")
    dataset = [q for q in dataset if q.get("livebench_release_date", "") <= release]
    
    # –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ
    train_ratio = config.get("train_ratio", 0.7)
    val_ratio = config.get("validation_ratio", 0.15)
    seed = config.get("split_seed", 42)
    
    random.seed(seed)
    random.shuffle(dataset)
    
    n = len(dataset)
    train_end = int(n * train_ratio)
    val_end = int(n * (train_ratio + val_ratio))
    
    train = dataset[:train_end]
    val = dataset[train_end:val_end]
    test = dataset[val_end:]
    
    _DATASET_SPLITS[cache_key] = {"train": train, "validation": val, "test": test}
    print(f"LiveBench IF split: Train={len(train)}, Val={len(val)}, Test={len(test)}")
    
    return train, val, test


def evaluate_single_example(
    prompt_template: str,
    example: Dict[str, Any],
    client,
    model_name: str
) -> Tuple[float, Dict]:
    """
    –û—Ü–µ–Ω–∫–∞ –æ–¥–Ω–æ–≥–æ –ø—Ä–∏–º–µ—Ä–∞ –∏—Å–ø–æ–ª—å–∑—É—è –û–§–ò–¶–ò–ê–õ–¨–ù–´–ï —Å–∫—Ä–∏–ø—Ç—ã LiveBench.
    """
    # –§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –ø—Ä–æ–º–ø—Ç–∞
    instruction = example["turns"][0]
    formatted_prompt = prompt_template.format(instruction=instruction)
    
    # –ü–æ–ª—É—á–µ–Ω–∏–µ –æ—Ç–≤–µ—Ç–∞ –º–æ–¥–µ–ª–∏
    response = client.chat.completions.create(
        model=model_name,
        messages=[{"role": "user", "content": formatted_prompt}],
        temperature=0.1,
        max_tokens=4096
    )
    model_response = response.choices[0].message.content.strip()
    
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ñ–æ—Ä–º–∞—Ç –∑–∞–¥–∞—á–∏
    task = example.get("task", "")
    
    if "ifbench" in task.lower():
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º IFBench –æ—Ü–µ–Ω–∫—É
        score = ifbench_process_results(example, model_response, debug=False)
    else:
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º IFEval –æ—Ü–µ–Ω–∫—É
        inp = evaluation_main.InputExample(
            key=example.get("question_id", 0),
            instruction_id_list=example["instruction_id_list"],
            prompt=instruction,
            kwargs=example["kwargs"]
        )
        prompt_to_response = {instruction: model_response}
        result = evaluation_main.test_instruction_following_strict(inp, prompt_to_response)
        score = score_results(result.follow_all_instructions, result.follow_instruction_list)
    
    details = {
        "question_id": example.get("question_id"),
        "task": task,
        "score": score,
        "instruction_ids": example.get("instruction_id_list", [])
    }
    
    return score, details


def evaluate(program_path: str) -> Dict[str, Any]:
    """
    –ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –æ—Ü–µ–Ω–∫–∏ –¥–ª—è OpenEvolve.
    """
    # –ó–∞–≥—Ä—É–∑–∫–∞ –ø—Ä–æ–º–ø—Ç–∞
    with open(program_path, "r", encoding="utf-8") as f:
        prompt_template = f.read().strip()
    
    # –ó–∞–≥—Ä—É–∑–∫–∞ –∫–æ–Ω—Ñ–∏–≥–∞ –∏ –¥–∞—Ç–∞—Å–µ—Ç–∞
    config = load_config()
    train_dataset, _, _ = load_livebench_if_dataset(config)
    
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–ª–∏–µ–Ω—Ç–∞
    client = get_llm_client(config)
    model_name = config.get("model_name")
    
    # –ö–∞—Å–∫–∞–¥–Ω–∞—è –æ—Ü–µ–Ω–∫–∞
    use_cascade = config.get("evaluator", {}).get("cascade_evaluation", True)
    
    if use_cascade:
        # Stage 1
        stage1_samples = 10
        stage1_threshold = 0.6
        
        indices = random.sample(range(len(train_dataset)), min(stage1_samples, len(train_dataset)))
        scores = []
        for idx in indices:
            score, _ = evaluate_single_example(prompt_template, train_dataset[idx], client, model_name)
            scores.append(score)
        
        stage1_accuracy = sum(scores) / len(scores)
        
        if stage1_accuracy < stage1_threshold:
            return {
                "combined_score": stage1_accuracy * 0.5,
                "accuracy": stage1_accuracy,
                "stage": 1,
                "passed_stage1": False,
                **calculate_prompt_features(prompt_template)
            }
        
        # Stage 2
        stage2_samples = 40
        indices = random.sample(range(len(train_dataset)), min(stage2_samples, len(train_dataset)))
        scores = []
        for idx in indices:
            score, _ = evaluate_single_example(prompt_template, train_dataset[idx], client, model_name)
            scores.append(score)
        
        accuracy = sum(scores) / len(scores)
    else:
        # –ë–µ–∑ –∫–∞—Å–∫–∞–¥–∞
        indices = random.sample(range(len(train_dataset)), min(50, len(train_dataset)))
        scores = []
        for idx in indices:
            score, _ = evaluate_single_example(prompt_template, train_dataset[idx], client, model_name)
            scores.append(score)
        accuracy = sum(scores) / len(scores)
    
    # LLM Feedback (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
    llm_feedback = get_llm_feedback(prompt_template) if config.get("use_llm_feedback") else 0.0
    
    # Combined Score
    combined_score = 0.7 * accuracy + 0.3 * llm_feedback
    
    return {
        "combined_score": combined_score,
        "accuracy": accuracy,
        "llm_feedback": llm_feedback,
        **calculate_prompt_features(prompt_template),
        "stage": 2 if use_cascade else 0,
        "passed_stage1": True
    }
```

### –§–∞–∑–∞ 3: –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –∏ –∑–∞–ø—É—Å–∫ (1 —á–∞—Å)

#### 3.1. `livebench_prompt_dataset.yaml`

```yaml
# LiveBench Instruction Following dataset configuration
dataset_name: "livebench/instruction_following"
input_field: "turns"
target_field: "instruction_id_list"
split: "test"

# Dataset splitting
train_ratio: 0.7
validation_ratio: 0.15
test_ratio: 0.15
split_seed: 42

# LiveBench specific
livebench_release: "2024-11-25"
is_livebench: true
streaming: false
```

#### 3.2. `livebench_prompt.txt`

```
Follow the instruction below carefully and precisely. Pay attention to all requirements and constraints specified in the instruction.

Instruction: {instruction}

Response:
```

#### 3.3. `config.yaml`

```yaml
max_iterations: 100
checkpoint_interval: 10
log_level: "INFO"
diff_based_evolution: false
max_code_length: 10000
language: "text"

llm:
  api_base: "https://llm.api.cloud.yandex.net/v1"
  models:
    - name: "gpt://b1gemincl8p7b2uiv5nl/qwen3-235b-a22b-fp8/latest"
      weight: 1.0
  temperature: 0.8
  max_tokens: 4096
  timeout: 60
  retries: 3

database:
  population_size: 50
  archive_size: 500
  num_islands: 4
  feature_dimensions: ["prompt_length", "reasoning_strategy"]
  feature_bins: 10

evaluator:
  timeout: 1800
  max_retries: 3
  parallel_evaluations: 4
  cascade_evaluation: true
  cascade_thresholds: [0.6]
  use_llm_feedback: true
  llm_feedback_weight: 0.2

evolution_trace:
  enabled: true
  format: "jsonl"
  include_code: true
  include_prompts: true
```

### –§–∞–∑–∞ 4: –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –∏ –∞–Ω–∞–ª–∏–∑ (1-2 —á–∞—Å–∞)

–ö–æ–ø–∏—Ä—É–µ–º –∏ –∞–¥–∞–ø—Ç–∏—Ä—É–µ–º –∏–∑ `ifeval_experiment`:
- `visualize_evolution.py`
- `analyze_improvements.py`

---

## üìÅ –°—Ç—Ä—É–∫—Ç—É—Ä–∞ —Ñ–∞–π–ª–æ–≤ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞

```
livebench_experiment/
‚îú‚îÄ‚îÄ LiveBench/                          # –ö–ª–æ–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π (—É–∂–µ –µ—Å—Ç—å)
‚îú‚îÄ‚îÄ evaluator.py                        # üÜï –°–æ–∑–¥–∞—Ç—å
‚îú‚îÄ‚îÄ config.yaml                         # üÜï –°–æ–∑–¥–∞—Ç—å
‚îú‚îÄ‚îÄ livebench_prompt.txt                # üÜï –°–æ–∑–¥–∞—Ç—å
‚îú‚îÄ‚îÄ livebench_prompt_dataset.yaml       # üÜï –°–æ–∑–¥–∞—Ç—å
‚îú‚îÄ‚îÄ visualize_evolution.py              # üÜï –°–∫–æ–ø–∏—Ä–æ–≤–∞—Ç—å –∏ –∞–¥–∞–ø—Ç–∏—Ä–æ–≤–∞—Ç—å
‚îú‚îÄ‚îÄ analyze_improvements.py             # üÜï –°–∫–æ–ø–∏—Ä–æ–≤–∞—Ç—å –∏ –∞–¥–∞–ø—Ç–∏—Ä–æ–≤–∞—Ç—å
‚îú‚îÄ‚îÄ run_evolution.ps1                   # üÜï –°–æ–∑–¥–∞—Ç—å
‚îú‚îÄ‚îÄ requirements.txt                    # üÜï –°–æ–∑–¥–∞—Ç—å
‚îú‚îÄ‚îÄ README.md                           # üÜï –°–æ–∑–¥–∞—Ç—å
‚îú‚îÄ‚îÄ LIVEBENCH_ANALYSIS_REPORT.md        # ‚úÖ –≠—Ç–æ—Ç —Ñ–∞–π–ª
‚îî‚îÄ‚îÄ openevolve_output/                  # –ë—É–¥–µ—Ç —Å–æ–∑–¥–∞–Ω–∞ –ø—Ä–∏ –∑–∞–ø—É—Å–∫–µ
    ‚îú‚îÄ‚îÄ best/
    ‚îú‚îÄ‚îÄ checkpoints/
    ‚îú‚îÄ‚îÄ logs/
    ‚îî‚îÄ‚îÄ visualizations/
```

---

## üîë –ö–ª—é—á–µ–≤—ã–µ –æ—Ç–ª–∏—á–∏—è –æ—Ç ifeval_experiment

| –ê—Å–ø–µ–∫—Ç | ifeval_experiment | livebench_experiment |
|--------|------------------|---------------------|
| **–î–∞—Ç–∞—Å–µ—Ç** | Google IFEval | LiveBench IF (IFEval + IFBench) |
| **–°–∫—Ä–∏–ø—Ç—ã –æ—Ü–µ–Ω–∫–∏** | –û—Ç–¥–µ–ª—å–Ω—ã–π –º–æ–¥—É–ª—å | –í—Å—Ç—Ä–æ–µ–Ω—ã –≤ LiveBench |
| **–¢–∏–ø—ã –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–π** | 25 | 83 (25 + 58) |
| **–°–ª–æ–∂–Ω–æ—Å—Ç—å** | –°—Ä–µ–¥–Ω—è—è | –í—ã—à–µ |
| **–û–±–Ω–æ–≤–ª–µ–Ω–∏—è** | –ù–µ—Ç | –ï–∂–µ–º–µ—Å—è—á–Ω—ã–µ |
| **–§–æ—Ä–º–∞—Ç –≤–æ–ø—Ä–æ—Å–æ–≤** | `instruction_id_list` + `kwargs` | –ê–Ω–∞–ª–æ–≥–∏—á–Ω—ã–π |

---

## ‚ö° –ë—ã—Å—Ç—Ä—ã–π —Å—Ç–∞—Ä—Ç

```bash
# 1. –£—Å—Ç–∞–Ω–æ–≤–∫–∞ LiveBench
cd livebench_experiment/LiveBench
pip install -e .

# 2. –ó–∞–≥—Ä—É–∑–∫–∞ –≤–æ–ø—Ä–æ—Å–æ–≤
cd livebench
python download_questions.py

# 3. –ó–∞–ø—É—Å–∫ —ç–≤–æ–ª—é—Ü–∏–∏ (–ø–æ—Å–ª–µ —Å–æ–∑–¥–∞–Ω–∏—è —Ñ–∞–π–ª–æ–≤)
cd ..
python ../../openevolve-run.py \
  --initial-program livebench_prompt.txt \
  --evaluator evaluator.py \
  --config config.yaml \
  --max-iterations 100
```

---

## üìö –°—Å—ã–ª–∫–∏

- [LiveBench Paper](https://arxiv.org/abs/2406.19314)
- [LiveBench Leaderboard](https://livebench.ai/)
- [HuggingFace Datasets](https://huggingface.co/livebench)
- [IFBench Paper](https://arxiv.org/pdf/2507.02833)
- [–û—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π IFEval](https://github.com/google-research/google-research/tree/master/instruction_following_eval)

---

*–û—Ç—á—ë—Ç —Å–æ–∑–¥–∞–Ω: $(date)*
*–í–µ—Ä—Å–∏—è: 1.0*

